{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries \n",
    "import pymongo\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import seaborn as sns\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "inspections_df = 0\n",
    "inventory_df = 0\n",
    "violations_df = 0\n",
    "df = 0\n",
    "score = 0\n",
    "unstack = 0\n",
    "stats = 0\n",
    "prep_df = 0\n",
    "establishment_table = 0\n",
    "correlation_table = 0\n",
    "message = ''\n",
    "label_file_frame5 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating root for tkinter GUI, title and fixed size.\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('Summative Assessment')\n",
    "root.geometry(\"800x700\")\n",
    "root.pack_propagate(False)\n",
    "root.resizable(0,0)\n",
    "\n",
    "# Frame for Treeview \n",
    "frame1 = tk.LabelFrame(root, text=\"Client Data\")\n",
    "frame1.place(height=325,width=800)\n",
    "\n",
    "# Frame for table for inspection score - mean, median and mode\n",
    "file_frame = tk.LabelFrame(root,text=\"Inspection Score Visualization\")\n",
    "file_frame.place(height=180,width=355,rely=0.48,relx=0.04)\n",
    "\n",
    "# Frame for establishment graphic visualization \n",
    "file_frame2 = tk.LabelFrame(root,text=\"Establishment Violations Visualization\")\n",
    "file_frame2.place(height=180,width=355,rely=0.48,relx=0.52)\n",
    "# label for establishment frame\n",
    "label_file_frame2 = tk.Label(file_frame2,text='Establishments that have commited each type of violation')\n",
    "label_file_frame2.pack()\n",
    "\n",
    "# Frame for loading and saving dataset\n",
    "file_frame3 = tk.LabelFrame(root,text='File Manager')\n",
    "file_frame3.place(height=70,width=355,rely=0.877,relx=0.52)\n",
    "\n",
    "# Frame for Zip Code and Number of violations correlation visualization\n",
    "file_frame4 = tk.LabelFrame(root,text='Correlation Visualization')\n",
    "file_frame4.place(height=160,width=355,rely=0.74,relx=0.04)\n",
    "# Label for correlation visualization frame\n",
    "label_file_frame4 = tk.Label(file_frame4,text='Please input Vendor Name:')\n",
    "label_file_frame4.pack()\n",
    "\n",
    "# Frame message output\n",
    "file_frame5 = tk.LabelFrame(root)\n",
    "file_frame5.place(height=80,width=355,rely=0.75,relx=0.52)\n",
    "# Label for message output frame\n",
    "label_file_frame5 = ttk.Label(file_frame5,text='No File Loaded')\n",
    "label_file_frame5.place(rely=0,relx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# button created to load and clean initial dataset's\n",
    "load_clean_button = tk.Button(file_frame3,text=\"Load and clean dataset's\",command=lambda: load_and_clean_data())\n",
    "load_clean_button.place(rely=0.02,relx=0.08)\n",
    "\n",
    "# button created to show treeview table for yearly mean, median and mode values for each PE DESCRIPTION\n",
    "show_button = tk.Button(file_frame,text=\"Show Table\",command=lambda: Load_csv_data())\n",
    "show_button.place(rely=0.5,relx=0.4)\n",
    "\n",
    "# button created to save cleaned/prepared dataset\n",
    "save_button = tk.Button(file_frame3,text=\"Save prepared dataset\",command=lambda: save_dataset())\n",
    "save_button.place(rely=0.02,relx=0.55)\n",
    "\n",
    "# button created to load a saved prepared dataset\n",
    "load_prep_button = tk.Button(file_frame3,text=\"Load prepared dataset\",command=lambda: load_prepared_dataset())\n",
    "load_prep_button.place(rely=0.5,relx=0.33)\n",
    "\n",
    "# function created to output message to user including a box and label\n",
    "def message_box():\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    label_file_frame5 = ttk.Label(file_frame5,text=message)\n",
    "    label_file_frame5.place(rely=0,relx=0)\n",
    "   \n",
    "# function created to clear message box output when new message is displayed\n",
    "def message_delete():\n",
    "    global label_file_frame5\n",
    "    label_file_frame5.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treeview Widget created for inspection score statistical values \n",
    "tv1 = ttk.Treeview(frame1)\n",
    "tv1.place(relheight=1,relwidth=1)\n",
    "\n",
    "# scrollbar created for table - enables user to view and interact with entire dataset\n",
    "treescrolly = tk.Scrollbar(frame1,orient=\"vertical\",command=tv1.yview)\n",
    "treescrollx = tk.Scrollbar(frame1,orient=\"horizontal\",command=tv1.xview)\n",
    "tv1.configure(xscrollcommand=treescrollx.set, yscrollcommand=treescrolly.set)\n",
    "treescrollx.pack(side=\"bottom\",fill=\"x\")\n",
    "treescrolly.pack(side=\"right\",fill=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function created to convert .csv to .json\n",
    "def convert_to_json(file):\n",
    "    # .read_csv converts .csv into pandas dataframe\n",
    "    csv_data = pd.read_csv(file) \n",
    "    # convert to dictionary and values to lists\n",
    "    json_data = csv_data.to_dict('records') \n",
    "                                           \n",
    "    return json_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data():\n",
    "    global inspections_df \n",
    "    global inventory_df \n",
    "    global violations_df \n",
    "    global loaded\n",
    "    global df\n",
    "    global prep_df\n",
    "    global establishment_table\n",
    "    global message\n",
    "    global MongoDB\n",
    "    global group_zip\n",
    "    \n",
    "    startTime = time.time()\n",
    "\n",
    "    # connect to mongodb client and database\n",
    "    connection = pymongo.MongoClient(\"mongodb://localhost:27017/\") \n",
    "    # create a new database \n",
    "    MongoDB = connection[\"data\"] \n",
    "\n",
    "    # delete duplicate/multiple collections\n",
    "    ins_collection = MongoDB[\"inspections\"].delete_many({})\n",
    "    inv_collection = MongoDB[\"inventory\"].delete_many({})\n",
    "    vio_collection = MongoDB[\"violations\"].delete_many({})\n",
    "    \n",
    "    # new collections for each file to be loaded into the database\n",
    "    ins_collection = MongoDB[\"inspections\"]\n",
    "    inv_collection = MongoDB[\"inventory\"]\n",
    "    vio_collection = MongoDB[\"violations\"]\n",
    "\n",
    "    # insert json data into their respective collections\n",
    "    ins_collection.insert_many(convert_to_json('Inspections.csv'))\n",
    "    inv_collection.insert_many(convert_to_json('Inventroy.csv'))\n",
    "    vio_collection.insert_many(convert_to_json('Violations.csv'))\n",
    "\n",
    "    # individually convert all 3 collections into their own dataframes\n",
    "    # '_id' as false to remove the mongodb id references from each item\n",
    "    inspections_df = pd.DataFrame(list(ins_collection.find({}, {'_id': False})))\n",
    "    inventory_df = pd.DataFrame(list(inv_collection.find({}, {'_id': False})))\n",
    "    violations_df = pd.DataFrame(list(vio_collection.find({}, {'_id': False})))\n",
    "    \n",
    "\n",
    "    # remove duplicate \n",
    "    inspections_df.drop_duplicates(inplace=True) \n",
    "    inventory_df.drop_duplicates(inplace=True) \n",
    "    violations_df.drop_duplicates(inplace=True) \n",
    "    # Keep the required columns (columns that do not exist in inspections)\n",
    "    inventory_df = inventory_df[['RECORD ID','Zip Codes']]\n",
    "    # merge dataframe \n",
    "    df = pd.merge(inventory_df,inspections_df,on=['RECORD ID'],how='right')\n",
    "\n",
    "    # fill in missing data for zipcodes from Inventory into Inspections\n",
    "    df[\"Zip Codes\"] = df[\"Zip Codes_x\"].combine_first(df[\"Zip Codes_y\"])\n",
    "    df = df.drop([\"Zip Codes_x\", \"Zip Codes_y\"], axis=1)\n",
    "\n",
    "    # Filter dataset to ACTIVE only\n",
    "    df = df.loc[df['PROGRAM STATUS'] == 'ACTIVE']\n",
    "\n",
    "    # Remove missing values\n",
    "    df = df[df['SCORE'].notna()]\n",
    "    df = df[df['Zip Codes'].notna()]\n",
    "        \n",
    "    #Filter Dataframes\n",
    " \n",
    "    df = df[['FACILITY NAME','ACTIVITY DATE','SCORE','PROGRAM STATUS','PE DESCRIPTION','Zip Codes','SERIAL NUMBER']]\n",
    "\n",
    "    # extract information within brackets using regular expressions to create a new column\n",
    "    df['PE CODE'] = df['PE DESCRIPTION'].str.extract(r\"\\((.*?)\\)\", expand=False)\n",
    "    df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\"\\((.*?)\\)\",\"\")\n",
    "\n",
    "    # fix description name for LIC HTH CARE FOOD FAC HIGH RISK due to double spacing\n",
    "    df[\"PE DESCRIPTION\"]= df[\"PE DESCRIPTION\"].replace('LIC HTH CARE FOOD FAC  HIGH RISK', \n",
    "                                                       'LIC HTH CARE FOOD FAC HIGH RISK',inplace=False) \n",
    "    # convert activity date to datetime and create new column to sort by year\n",
    "    df['ACTIVITY DATE'] = pd.to_datetime(df['ACTIVITY DATE'])\n",
    "    ACT_YEAR = df['ACTIVITY DATE'].map(lambda x: x.year)\n",
    "    df['ACT_YEAR'] = ACT_YEAR\n",
    "    df['Zip Codes'] = df['Zip Codes'].astype(int)\n",
    "\n",
    "    # Create prepared dataframe\n",
    "    prep_df = pd.merge(violations_df,df,on=['SERIAL NUMBER'],how='right')\n",
    "    prep_df = prep_df[prep_df['VIOLATION CODE'].notna()]\n",
    "    group_zip = prep_df.copy()\n",
    "    group_zip['Zip Codes'] = group_zip['Zip Codes'].astype(str).str[:-2].astype(np.int64)\n",
    "    \n",
    "    message = \"Dataset's loaded and cleaned, ready to save.\"\n",
    "    message_box()   \n",
    "    \n",
    "    executionTime = (time.time() - startTime)\n",
    "    \n",
    "    print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset():\n",
    "    \n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    \n",
    "    connection = pymongo.MongoClient(\"mongodb://localhost:27017/\") #connect to local mongodb database\n",
    "    #connection.list_database_names()\n",
    "    try:\n",
    "        MongoDB = connection[\"data\"]\n",
    "        coll_names = MongoDB.list_collection_names()\n",
    "\n",
    "        if ('prepared data' not in coll_names) and (isinstance(prep_df,pd.DataFrame)):\n",
    "            save()\n",
    "            label_file_frame5.destroy()\n",
    "            message = 'Saved cleaned dataset'\n",
    "            message_box()\n",
    "\n",
    "        elif ('prepared data' in coll_names) and (isinstance(prep_df,pd.DataFrame)):\n",
    "            save()\n",
    "            label_file_frame5.destroy()\n",
    "            message = 'Existing prepared dataset overwrited'\n",
    "            message_box()\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        message_delete()\n",
    "        message = 'Prepared data already exists'\n",
    "        message_box()\n",
    "    \n",
    "def save():\n",
    "    \n",
    "    saved_collection = MongoDB[\"prepared data\"].delete_many({})\n",
    "    saved_collection = MongoDB[\"prepared data\"]\n",
    "    df_save = prep_df.to_json(orient=\"records\")\n",
    "    parsed = json.loads(df_save)\n",
    "    saved_collection.insert_many(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepared_dataset():\n",
    "    \n",
    "    global prep_df\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    global group_zip\n",
    "    \n",
    "    connection = pymongo.MongoClient(\"mongodb://localhost:27017/\") #connect to local mongodb database\n",
    "    MongoDB = connection[\"data\"]\n",
    "    \n",
    "    coll_names = MongoDB.list_collection_names()\n",
    "    \n",
    "    if 'prepared data' not in coll_names:\n",
    "        message_delete()\n",
    "        message = 'Prepared data does not exist'\n",
    "        message_box()\n",
    "        \n",
    "    elif 'prepared data' in coll_names:\n",
    "        \n",
    "        prepared_dataset = MongoDB[\"prepared data\"]\n",
    "        prep_df = pd.DataFrame(list(prepared_dataset.find({}, {'_id': False})))\n",
    "        group_zip = prep_df.copy()\n",
    "        group_zip['Zip Codes'] = group_zip['Zip Codes'].astype(str).str[:-2].astype(np.int64)\n",
    "        \n",
    "        message_delete()\n",
    "        message = 'Prepared data loaded'\n",
    "        message_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "           \"Vendor's seating - Mean inspection score per year\",\n",
    "           \"Vendor's seating - Mode inspection score per year\",\n",
    "           \"Vendor's seating - Median inspection score per year\",\n",
    "            'Zip Code - Mean inspection score per year',\n",
    "            'Zip Code - Mode inspection score per year',\n",
    "            'Zip Code - Median inspection score per year',]\n",
    "\n",
    "clicked = tk.StringVar()\n",
    "clicked.set(options[0])\n",
    "\n",
    "drop = tk.OptionMenu(file_frame, clicked, *options)\n",
    "drop.place(rely=0.2,relx=0.01)\n",
    "\n",
    "def Load_csv_data():\n",
    "\n",
    "    global score\n",
    "    global stats\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "   \n",
    "    options_clicked = clicked.get()\n",
    "    \n",
    "    try:\n",
    "        if options_clicked == \"Vendor's seating - Mean inspection score per year\":\n",
    "            stats = prep_df.groupby(['ACT_YEAR','PE DESCRIPTION'])[['SCORE']].mean()\n",
    "            pe_description_data_manipulate()\n",
    "\n",
    "        elif options_clicked == \"Vendor's seating - Mode inspection score per year\":\n",
    "            stats = prep_df.groupby(['ACT_YEAR','PE DESCRIPTION'])[['SCORE']].agg(lambda x:x.value_counts().index[0])\n",
    "            pe_description_data_manipulate()\n",
    "\n",
    "        elif options_clicked == \"Vendor's seating - Median inspection score per year\":\n",
    "            stats = prep_df.groupby(['ACT_YEAR','PE DESCRIPTION'])[['SCORE']].median()\n",
    "            pe_description_data_manipulate()\n",
    "\n",
    "        elif options_clicked == 'Zip Code - Mean inspection score per year':\n",
    "            stats = prep_df.groupby(['ACT_YEAR','Zip Codes'])[['SCORE']].mean()\n",
    "            zipcode_data_manipulate()\n",
    "\n",
    "        elif options_clicked == 'Zip Code - Mode inspection score per year':\n",
    "            stats = prep_df.groupby(['ACT_YEAR','Zip Codes'])[['SCORE']].agg(lambda x:x.value_counts().index[0])\n",
    "            zipcode_data_manipulate()\n",
    "\n",
    "        elif options_clicked == 'Zip Code - Median inspection score per year':\n",
    "            stats = prep_df.groupby(['ACT_YEAR','Zip Codes'])[['SCORE']].median()\n",
    "            zipcode_data_manipulate()\n",
    "\n",
    "        clear_data()\n",
    "        tv1[\"column\"] = list(score.columns)\n",
    "        tv1[\"show\"] = \"headings\"\n",
    "\n",
    "        for column in tv1[\"columns\"]:\n",
    "            tv1.heading(column,text=column)\n",
    "\n",
    "        df_rows = score.to_numpy().tolist()\n",
    "        for row in df_rows:\n",
    "            tv1.insert(\"\",\"end\",values=row)\n",
    "        return None\n",
    "    \n",
    "    except:\n",
    "        message_delete()\n",
    "        message = 'Please load new dataset or a prepared dataset'\n",
    "        message_box()\n",
    "\n",
    "def zipcode_data_manipulate():\n",
    "    \n",
    "    global score\n",
    "    global unstack\n",
    "    global stats\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    \n",
    "    try:\n",
    "        unstack = stats.unstack(0).reset_index()\n",
    "        score = unstack['SCORE'].round(2)\n",
    "        score['Zip Codes'] = unstack['Zip Codes']\n",
    "        first_col =score.pop('Zip Codes')\n",
    "        score.insert(0,'Zip Codes',first_col)\n",
    "        score.columns.name = None\n",
    "        score.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    except: \n",
    "        message_delete()\n",
    "        message = 'Please load new dataset or a prepared dataset'\n",
    "        message_box()\n",
    "    \n",
    "def pe_description_data_manipulate():\n",
    "    \n",
    "    global score\n",
    "    global unstack\n",
    "    global stats\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    \n",
    "    try:\n",
    "        unstack = stats.unstack(0).reset_index()\n",
    "        score = unstack['SCORE'].round(2)\n",
    "        score['PE DESCRIPTION'] = unstack['PE DESCRIPTION']\n",
    "        first_col = score.pop('PE DESCRIPTION')\n",
    "        score.insert(0,'PE DESCRIPTION',first_col)\n",
    "        score.columns.name = None\n",
    "        score.reset_index(drop=True, inplace=True)\n",
    "    except:\n",
    "        message_delete()\n",
    "        message = 'Please load new dataset or a prepared dataset'\n",
    "        message_box()\n",
    "    \n",
    "def clear_data():\n",
    "    tv1.delete(*tv1.get_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked2 = tk.StringVar()\n",
    "clicked2.set(None)\n",
    "\n",
    "MODES = [\n",
    "    (\"10000+\",\"10000+\"),\n",
    "    (\"1000-10000\",\"1000-10000\"),\n",
    "    (\"100-1000\",\"100-1000\"),\n",
    "    (\"2-100\",\"2-100\"),\n",
    "    (\"1\",\"1\")\n",
    "]\n",
    "\n",
    "for text, mode in MODES:\n",
    "    tk.Radiobutton(file_frame2,text=text, variable=clicked2,value=mode).pack(anchor=tk.N)\n",
    "    \n",
    "button3 = tk.Button(file_frame2,text=\"Load Graph\",command=lambda: graphvis())\n",
    "button3.pack()\n",
    "\n",
    "def graphvis():\n",
    "    #global variables for message output\n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    # try-except implemented for error handling - when dataset is not loaded by user \n",
    "    try:\n",
    "        # dataframe manipulation for matplotlib visualisation, multi-index level reset and values sorted.\n",
    "        establishment_table = prep_df.groupby(['VIOLATION CODE'])[['FACILITY NAME']].nunique()\n",
    "        establishment_table = establishment_table.reset_index()\n",
    "        establishment_table = establishment_table.sort_values('FACILITY NAME',ascending = False)\n",
    "        \n",
    "        # variable assigned for grabbing the string variable for radio button selected.\n",
    "        mode_clicked = clicked2.get()\n",
    "        rnge = 0\n",
    "        \n",
    "        # creating a new tkinter window for matplotlib graph, set the title and window size. \n",
    "        graph = tk.Tk()\n",
    "        graph.title('Number of establishments that have commited each type of violation')\n",
    "        graph.geometry(\"1200x600\")\n",
    "\n",
    "        # group the data into different ranges to make visualisationâ€™s feasible\n",
    "        highest = establishment_table[(establishment_table['FACILITY NAME'] >= 10000)]\n",
    "        high = establishment_table[(establishment_table['FACILITY NAME'] <= 10000) & \n",
    "                                   (establishment_table['FACILITY NAME'] >= 1000) ]\n",
    "        mid = establishment_table[(establishment_table['FACILITY NAME'] <= 1000) & \n",
    "                                  (establishment_table['FACILITY NAME'] >= 100) ]\n",
    "        low = establishment_table[(establishment_table['FACILITY NAME'] <= 100) & \n",
    "                                  (establishment_table['FACILITY NAME'] >= 2) ]\n",
    "        lowest = establishment_table[(establishment_table['FACILITY NAME'] < 2)]\n",
    "        \n",
    "        # if statement to select different ranges according to a set of conditions\n",
    "        if mode_clicked == \"10000+\":\n",
    "            rnge = highest\n",
    "        elif mode_clicked == \"1000-10000\":\n",
    "            rnge = high\n",
    "        elif mode_clicked == \"100-1000\":\n",
    "            rnge = mid \n",
    "        elif mode_clicked == \"2-100\":\n",
    "            rnge = low\n",
    "        elif mode_clicked == \"1\":\n",
    "            rnge = lowest\n",
    "        \n",
    "        # Create matplotlib figure and set the size.\n",
    "        fig = plt.Figure(figsize=(50,10),dpi=100)\n",
    "        # Bar chart style selected, x and y axis are plotted, additional styling and renaming applied \n",
    "        fig.add_subplot(111).bar(rnge['VIOLATION CODE'],rnge['FACILITY NAME'],color='blue')\n",
    "        fig.autofmt_xdate(rotation=90)\n",
    "        fig.text(0.5, 0.04, 'Violation Codes', ha='center')\n",
    "        fig.text(0.04, 0.5, 'Number of Establishments', va='center', rotation='vertical')\n",
    "        # Imported canvas from enabling matplotlib and tkinter integration \n",
    "        chart = FigureCanvasTkAgg(fig,graph)\n",
    "        chart.get_tk_widget().pack()\n",
    "        \n",
    "    except:\n",
    "        # Exception handling when no dataset is loaded\n",
    "        message_delete()\n",
    "        message = 'Please load new dataset or a prepared dataset'\n",
    "        message_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked3 = tk.StringVar()\n",
    "clicked3.set('Grouped Locations')\n",
    "\n",
    "selection = [\n",
    "    (\"Grouped Locations\",\"Grouped Locations\"),\n",
    "    (\"Individual Locations\",'Individual Locations'),\n",
    "]\n",
    "\n",
    "for text, mode in selection:\n",
    "    tk.Radiobutton(file_frame4,text=text, variable=clicked3,value=mode).pack(anchor=tk.N)\n",
    "\n",
    "# create user input box for facility/owner ID information\n",
    "e = tk.Entry(file_frame4,width=30,)\n",
    "e.insert(0,'subway')\n",
    "e.pack()\n",
    "\n",
    "# create a button to load the seaborn visualisation\n",
    "button4 = tk.Button(file_frame4,text=\"Load Graph\",command=lambda: correlation_plot())\n",
    "button4.pack()\n",
    "\n",
    "def correlation_plot():\n",
    "    \n",
    "    global message\n",
    "    global label_file_frame5\n",
    "    global prep_df\n",
    "    global facility_input\n",
    "    \n",
    "    # variables for selected column names and vendor/facility names \n",
    "    locations_grouping = 0\n",
    "    facility_input = 0\n",
    "    \n",
    "    # .get() to grab radio button string value and assign as variable\n",
    "    mode_clicked = clicked3.get()\n",
    "    # .get() to grab user input string and assign as variable\n",
    "    facility_input = e.get()\n",
    "    \n",
    "    # if statement for radio button choices\n",
    "    if mode_clicked == \"Grouped Locations\":\n",
    "        locations_grouping = group_zip\n",
    "    elif mode_clicked == \"Individual Locations\":\n",
    "        locations_grouping = prep_df\n",
    "\n",
    "    try:\n",
    "        # filtering and shaping data frame for seaborn visualisation, cosisting of groupby and reset_index()\n",
    "        correlation_table = locations_grouping.loc[locations_grouping['FACILITY NAME'] == facility_input.upper()]\n",
    "        correlation_table = correlation_table.groupby(['FACILITY NAME','Zip Codes'])['VIOLATION CODE'].count()\n",
    "        correlation_table = correlation_table.reset_index()\n",
    "\n",
    "        # create a tkinter window for the seaborn bar chart\n",
    "        graph = tk.Tk()\n",
    "        graph.title(\"Seaborn bar chart graphical visualisation\")\n",
    "        graph.geometry(\"1200x600\")\n",
    "        sns.set(style=\"whitegrid\")\n",
    "\n",
    "        # Set up the seaborn figure \n",
    "        f, ax = plt.subplots(figsize=(50, 10))\n",
    "        # Draw the barplot and label title and axis\n",
    "        g = sns.barplot(x=\"Zip Codes\", y=\"VIOLATION CODE\", data=correlation_table)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel(\"Number of Violations\")\n",
    "        plt.xlabel(facility_input + ' Zip Codes')\n",
    "        plt.title(\"Number of violations that have been commited by each \" + facility_input + \" location\")\n",
    "        # A tk.DrawingArea\n",
    "        chart = FigureCanvasTkAgg(f, graph)  \n",
    "        chart.get_tk_widget().pack()\n",
    "    except:\n",
    "        # Exception handling when no dataset is loaded\n",
    "        message_delete()\n",
    "        message = 'Please load new dataset or an existing prepared dataset'\n",
    "        message_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-4-61fe1aba1f97>\", line 2, in <lambda>\n",
      "    load_clean_button = tk.Button(file_frame3,text=\"Load and clean dataset's\",command=lambda: load_and_clean_data())\n",
      "  File \"<ipython-input-7-1c143425e019>\", line 31, in load_and_clean_data\n",
      "    ins_collection.insert_many(convert_to_json('Inspections.csv'))\n",
      "  File \"<ipython-input-6-ed369cc3b99f>\", line 4, in convert_to_json\n",
      "    csv_data = pd.read_csv(file)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File Inspections.csv does not exist: 'Inspections.csv'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-4-61fe1aba1f97>\", line 2, in <lambda>\n",
      "    load_clean_button = tk.Button(file_frame3,text=\"Load and clean dataset's\",command=lambda: load_and_clean_data())\n",
      "  File \"<ipython-input-7-1c143425e019>\", line 31, in load_and_clean_data\n",
      "    ins_collection.insert_many(convert_to_json('Inspections.csv'))\n",
      "  File \"<ipython-input-6-ed369cc3b99f>\", line 4, in convert_to_json\n",
      "    csv_data = pd.read_csv(file)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/eric/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File Inspections.csv does not exist: 'Inspections.csv'\n"
     ]
    }
   ],
   "source": [
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
